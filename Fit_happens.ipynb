{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Fitting probability distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Fitting probability distributions to data is an important task in any discipline of science and engineering, as these distributions can be used to derive quantitative statements about risks and frequencies of uncertain properties. Probabilistic tools can be applied to model this uncertainty. In this workshop, you will work with a dataset of your choosing estimate a distribution and evaluate the quality of your fit.\n",
    "\n",
    "**The goal of this project is:**\n",
    "1. Choose a reasonable distribution function for your chosen dataset, analyzing the statistics of the observations.\n",
    "2. Fit the chosen distributions by moments.\n",
    "3. Assess the fit computing probabilities analytically.\n",
    "4. Assess the fit using goodness of fit techniques and computer code.\n",
    "\n",
    "The project will be divided into 3 parts: 1) data analysis, 2) pen and paper stuff (math practice!), and 3) programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let us load some required libraries \n",
    "import numpy as np                       # For math\n",
    "import matplotlib.pyplot as plt          # For plotting\n",
    "from matplotlib.gridspec import GridSpec # For plotting\n",
    "import pandas as pd                      # For file-wrangling\n",
    "from scipy import stats                  # For math\n",
    "\n",
    "# This is just cosmetic - it updates the font size for our plots\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please choose one of the following datasets:**\n",
    "1. Observations of the **compressive strength of concrete**. The compressive strength of concrete is key for the safety of infrastructures and buildings. However, a lot of boundary conditions influence the final resistance of the concrete, such the cement content, the environmental temperature or the age of the concrete. (You can read more about the dataset [here](https://www.kaggle.com/datasets/gauravduttakiit/compressive-strength-of-concrete))\n",
    "2. ERA5 predictions of the **hourly temperature at 2m height** during the summer months (June, July, August) from 2005 to 2025. ERA5 predictions are re-analysis data, which are observation-corrected weather model predictions. Like most climate data, they depend on chaotic global weather dynamics, which precise long-term predictions difficult. (The data set is extracted from [here](https://archive-api.open-meteo.com/v1/era5?latitude=52.00667&longitude=4.35556&start_date=2005-01-01&end_date=2024-12-31&hourly=temperature_2m&timezone=Europe%2FAmsterdam).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# This function searches for the data files we require, and downloads them from a server if unsuccessful\n",
    "def findfile(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(f\"Downloading {fname}...\")\n",
    "        urlretrieve('https://github.com/TUDelft-MUDE/source-files/raw/main/file/'+fname, fname)\n",
    "\n",
    "# We download two datasets for concrete and temperature data\n",
    "findfile('dataset_concrete.csv')\n",
    "findfile('dataset_temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please choose one of the datasets below\n",
    "viable_datasets = ['concrete','temperature']\n",
    "dataset = 'concrete' # Choose one dataset from the list above\n",
    "\n",
    "# Automated check to see if the user selection is viable\n",
    "assert dataset in viable_datasets, \"Dataset must be in {}. You have selected {}.\".format(str(viable_datasets),dataset)\n",
    "\n",
    "# Load the data\n",
    "data = np.genfromtxt('dataset_{}.csv'.format(dataset), skip_header=1)\n",
    "\n",
    "# Set the axis labels for the dataset\n",
    "if dataset == \"concrete\":\n",
    "    label = \"Concrete compressive strength [MPa]\"\n",
    "    number_bins = 10 # Depending on the number of data points, we may want to use different bin numbers for the histogram\n",
    "elif dataset == \"temperature\":\n",
    "    label = \"Summer air temperature in Delft [Â°C]\"\n",
    "    number_bins = 20 # Depending on the number of data points, we may want to use different bin numbers for the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us clean and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data by removing all NaN entries\n",
    "data = data[~np.isnan(data)]\n",
    "\n",
    "# Create a figure that shows the time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# GridSpec allows you to specify the size and relative positions of subplots, which can be very useful for plotting\n",
    "gs = GridSpec(\n",
    "    nrows = 1, # We want one row\n",
    "    ncols = 2, # We want two columns\n",
    "    width_ratios = [1,0.2]) # The second column should only be 20% as wide as the first column\n",
    "\n",
    "# In the first subplot, we plot the raw data series\n",
    "plt.subplot(gs[0,0])\n",
    "plt.plot(data,'ok')\n",
    "plt.xlabel(\"observation number\")\n",
    "plt.ylabel(label)\n",
    "ylims = plt.gca().get_ylim()\n",
    "\n",
    "# In the second subplot, we plot the histogram\n",
    "plt.subplot(gs[0,1])\n",
    "plt.hist(data, orientation='horizontal', color='lightblue', rwidth=0.9, bins = number_bins)\n",
    "plt.xlabel(\"frequency\")\n",
    "plt.gca().set_ylim(ylims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, you can see all the observations of your chosen dataset. You can see that there is no clear pattern in the observations. Let's see how the statistics look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "df_describe = pd.DataFrame(data)\n",
    "df_describe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 1.1:</b>   \n",
    "    Using <b>ONLY</b> the statistics calculated in the previous lines:\n",
    "    <li>Choose an appropriate distribution to model the data between the following: (1) Gumbel, (2) Uniform, and (3) Gaussian. </li>\n",
    "    <li>Justiy your choice.</li>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Use pen and paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have selected the appropriate distribution, you are going to fit it by moments manually and check the fit by computing some probabilities analytically. Remember that you have all the information you need in the textbook. Do not use any computer code for this section, you have to do in with pen and paper. You can use the notebook as a calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2.1:</b>   \n",
    "Fit the selected distribution by moments.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the fit by computing manually some probabilities from the fitted distribution and comparing them with the empirical ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2.2:</b>   \n",
    "Check the fit of the distribution:\n",
    "    <li>Use the values obtained from the statistical inspection: the min, 25%, 50%, 75% and max values. What are the non-exceedance probabilities (from the empirical distribution) that correspond to those values?</li>\n",
    "    <li>Compute the values of the random variable corresponding to those probabilities using the fitted distribution.</li>\n",
    "    <li>Compare the obtained values with the empirical ones and assess the fit.</li>\n",
    "</p>\n",
    "You can summarize your answers in the following table (report your values with 3-4 significant digits max, as needed).\n",
    "</p>\n",
    "\n",
    "<b>Tip:</b> To compute the minimum value and maximum value for the predicted quantiles, you can use the expected minimum and maximum values for a dataset of the same size of your observations. Recall how the computed the non-exceedance probability of the first and last rank samples in an empirical CDF.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   |Minimum value|P25%|P50%|P75%|Maximum value|\n",
    "|---|-------------|----|----|----|-------------|\n",
    "|Non-exceedance probability [$-$]| | 0.25 | 0.50 | 0.75 |  |\n",
    "|Empirical quantiles | | | | | |\n",
    "|Predicted quantiles ||||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Let's do it with Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's assess the performance using further goodness of fit metrics and see whether they are consistent with the previously done analysis. Note that you have the pseudo-code for the empirical CDF in the [reader](https://mude.citg.tudelft.nl/book/2025/univariate_distributions/empirical.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.1:</b>   \n",
    "Prepare a function to compute the empirical cumulative distribution function.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# def ecdf(YOUR_CODE_HERE):\n",
    "#     \"\"\"Write a function that returns [non_exceedance_probabilities, sorted_values].\"\"\"\n",
    "#     YOUR_CODE_HERE # may be more than one line\n",
    "#     return [non_exceedance_probabilities, sorted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.2:</b>   \n",
    "Transform the parameters of the selected distribution you fitted by moments to loc-scale-shape.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Hint: the distributions are listed in our [online textbook](https://mude.citg.tudelft.nl/book/2025/univariate_distributions/summary.html), but it is also critical to make sure that the formulation in the book is identical to that of the Python package we are using. You can do this by finding the page of the relevant distribution in the [Scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:95%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.3:</b>   \n",
    "Assess the goodness of fit of the distribution you fitted using the method of moments by:\n",
    "    <li> Visually comparing the empirical and fitted PDF.</li>\n",
    "    <li> Using the exceedance plot in log-scale.</li>\n",
    "    <li> Using the QQplot.</li>\n",
    "    <li> Interpret them. Do you reach a conclusion similar to that in the previous section?</li>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Hint: Use [Scipy](https://docs.scipy.org/doc/scipy/reference/stats.html)'s built in functions (watch out for the definition of the parameters!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# loc = YOUR_CODE_HERE\n",
    "# scale = YOUR_CODE_HERE\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# axes.hist(YOUR_CODE_HERE,\n",
    "#           edgecolor='k', linewidth=0.2, color='cornflowerblue',\n",
    "#           label='Empirical PDF', density = True, bins = number_bins)\n",
    "# axes.plot(YOUR_CODE_HERE, YOUR_CODE_HERE,\n",
    "#           'k', linewidth=2, label='YOUR_DISTRIBUTION_NAME_HERE PDF')\n",
    "# axes.set_xlabel(label)\n",
    "# axes.set_title('PDF', fontsize=18)\n",
    "# axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# axes.step(YOUR_CODE_HERE, YOUR_CODE_HERE, \n",
    "#           color='k', label='Empirical PDF')\n",
    "# axes.plot(YOUR_CODE_HERE, YOUR_CODE_HERE,\n",
    "#           color='cornflowerblue', label='YOUR_DISTRIBUTION_NAME_HERE PDF')\n",
    "# axes.set_xlabel(label)\n",
    "# axes.set_ylabel('${P[X > x]}$')\n",
    "# axes.set_title('Exceedance probability in log-scale', fontsize=18)\n",
    "# axes.set_yscale('log')\n",
    "# axes.legend()\n",
    "# axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# axes.scatter(YOUR_CODE_HERE, YOUR_CODE_HERE, \n",
    "#              color='cornflowerblue', label='Gumbel')\n",
    "# axes.set_xlabel('Observed '+label)\n",
    "# axes.set_ylabel('Estimated '+label)\n",
    "# axes.set_title('QQplot', fontsize=18)\n",
    "# xlims = axes.get_xlim()\n",
    "# ylims = axes.get_ylim()\n",
    "# axes.plot([np.min([xlims[0],ylims[0]]), np.max([xlims[1],ylims[1]])], [np.min([xlims[0],ylims[0]]), np.max([xlims[1],ylims[1]])], 'k')\n",
    "# axes.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "> By Max Ramgraber, Patricia Mares Nasarre and Robert Lanzafame, Delft University of Technology. CC BY 4.0, more info [on the Credits page of Workbook](https://mude.citg.tudelft.nl/workbook-2025/credits.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
